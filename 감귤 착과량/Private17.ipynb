{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Utility\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Preprocessing & Feature Engineering\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "\n",
    "# Evaluation\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Optuna\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "from optuna import Trial\n",
    "\n",
    "# Modeling\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "# Visualization\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "pd.set_option('mode.chained_assignment',  None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(r'C:\\Users\\dlwks\\OneDrive\\바탕 화면\\VSCode\\DACON_CODE_REVIEW\\감귤 착과량\\train.csv')\n",
    "test = pd.read_csv(r'C:\\Users\\dlwks\\OneDrive\\바탕 화면\\VSCode\\DACON_CODE_REVIEW\\감귤 착과량\\test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def print_mode(df, col):\n",
    "    cnt = Counter(df[col])\n",
    "    list_cnt = cnt.most_common(3)\n",
    "\n",
    "    for idx, value in enumerate(list_cnt):\n",
    "\n",
    "        print(f'{col}의 최빈값 {idx + 1}순위 : {value[0]} & {value[-1]}개')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_statistics(df, col):\n",
    "\n",
    "    max = df['착과량(int)'].max()\n",
    "    min = df['착과량(int)'].min()\n",
    "    mean = df['착과량(int)'].mean()\n",
    "    median = df['착과량(int)'].median()\n",
    "\n",
    "    print(f'{col}의 최대값 : {max}')\n",
    "    print(f'{col}의 최소값 : {max}')\n",
    "    print(f'{col}의 평균값 : {max}')\n",
    "    print(f'{col}의 중앙값 : {max}')\n",
    "    \n",
    "    print_mode(df, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_hist(df, col):\n",
    "\n",
    "    sns.histplot(data = df[col], kde = True)\n",
    "    print_statistics(df, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "identify_hist(train, '착과량(int)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train['착과량(int)']\n",
    "X_drop_list = ['ID']\n",
    "X_train = train.drop(X_drop_list, axis = 1)\n",
    "X_test = test.drop(['ID'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_corr = train.corr().abs().sort_values(by = '착과량(int)', ascending = False).iloc[:,:1]\n",
    "features_name = high_corr[high_corr['착과량(int)'] > 0.9].index\n",
    "features_name = list(features_name)\n",
    "features_name.remove('착과량(int)')\n",
    "X, y = X_train.drop(['착과량(int)'], axis = 1), X_train['착과량(int)']\n",
    "\n",
    "X_1 = X[features_name]\n",
    "X_test_1 = X_test[features_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1 = X_1.apply(lambda x : x.clip(x.quantile(.01), x.quantile(.99)), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(['착과량(int)'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['9월_새순_mean'] = X_train.iloc[:,4:34].mean(axis = 1)\n",
    "X_train['9월_새순_std'] = X_train.iloc[:,4:34].std(axis = 1)\n",
    "X_train['9월_새순_var'] = X_train.iloc[:,4:34].var(axis = 1)\n",
    "X_train['10월_새순_mean'] = X_train.iloc[:,34:65].mean(axis = 1)\n",
    "X_train['10월_새순_std'] = X_train.iloc[:,34:65].std(axis = 1)\n",
    "X_train['10월_새순_var'] = X_train.iloc[:,34:65].var(axis = 1)\n",
    "X_train['11월_새순_mean'] = X_train.iloc[:,65:93].mean(axis = 1)\n",
    "X_train['11월_새순_std'] = X_train.iloc[:,65:93].std(axis = 1)\n",
    "X_train['11월_새순_var'] = X_train.iloc[:,65:93].var(axis = 1)\n",
    "X_train['9월_엽록소_mean'] = X_train.iloc[:,93:123].mean(axis = 1)\n",
    "X_train['9월_엽록소_std'] = X_train.iloc[:,93:123].std(axis = 1)\n",
    "X_train['9월_엽록소_var'] = X_train.iloc[:,93:123].var(axis = 1)\n",
    "X_train['10월_엽록소_mean'] = X_train.iloc[:,123:154].mean(axis = 1)\n",
    "X_train['10월_엽록소_std'] = X_train.iloc[:,123:154].std(axis = 1)\n",
    "X_train['10월_엽록소_var'] = X_train.iloc[:,123:154].var(axis = 1)\n",
    "X_train['11월_엽록소_mean'] = X_train.iloc[:,154:182].mean(axis = 1)\n",
    "X_train['11월_엽록소_std'] = X_train.iloc[:,154:182].std(axis = 1)\n",
    "X_train['11월_엽록소_var'] = X_train.iloc[:,154:182].var(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['새순max'] = X_train.iloc[:,4:93].max(axis=1)\n",
    "X_train['새순min'] = X_train.iloc[:,4:93].min(axis=1)\n",
    "X_train['엽록소max'] = X_train.iloc[:,93:182].max(axis=1)\n",
    "X_train['엽록소min'] = X_train.iloc[:,93:182].min(axis=1)\n",
    "X_train['새순차이'] = X_train['새순max']-X_train['새순min']\n",
    "X_train['엽록소차이'] = X_train['엽록소max']-X_train['엽록소min']\n",
    "X_train['수고X수관폭'] = X_train['수고(m)']*X_train['수관폭평균']\n",
    "X_train['수관폭차이'] = X_train['수관폭2(max)']-X_train['수관폭1(min)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,89):\n",
    "    X_train[f'새순 + 엽록소_{i}'] = X_train.iloc[:,4:93].iloc[:,i] + X_train.iloc[:,93:182].iloc[:,i]\n",
    "for i in range(0,89):\n",
    "    X_train[f'새순 - 엽록소_{i}'] = X_train.iloc[:,4:93].iloc[:,i] - X_train.iloc[:,93:182].iloc[:,i]\n",
    "for i in range(0,89):\n",
    "    X_train[f'새순 * 엽록소_{i}'] = X_train.iloc[:,4:93].iloc[:,i] * X_train.iloc[:,93:182].iloc[:,i]\n",
    "for i in range(0,89):\n",
    "    X_train[f'새순 / 엽록소_{i}'] = X_train.iloc[:,4:93].iloc[:,i] / X_train.iloc[:,93:182].iloc[:,i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['9월_새순_mean'] = X_test.iloc[:,4:34].mean(axis = 1)\n",
    "X_test['9월_새순_std'] = X_test.iloc[:,4:34].std(axis = 1)\n",
    "X_test['9월_새순_var'] = X_test.iloc[:,4:34].var(axis = 1)\n",
    "X_test['10월_새순_mean'] = X_test.iloc[:,34:65].mean(axis = 1)\n",
    "X_test['10월_새순_std'] = X_test.iloc[:,34:65].std(axis = 1)\n",
    "X_test['10월_새순_var'] = X_test.iloc[:,34:65].var(axis = 1)\n",
    "X_test['11월_새순_mean'] = X_test.iloc[:,65:93].mean(axis = 1)\n",
    "X_test['11월_새순_std'] = X_test.iloc[:,65:93].std(axis = 1)\n",
    "X_test['11월_새순_var'] = X_test.iloc[:,65:93].var(axis = 1)\n",
    "X_test['9월_엽록소_mean'] = X_test.iloc[:,93:123].mean(axis = 1)\n",
    "X_test['9월_엽록소_std'] = X_test.iloc[:,93:123].std(axis = 1)\n",
    "X_test['9월_엽록소_var'] = X_test.iloc[:,93:123].var(axis = 1)\n",
    "X_test['10월_엽록소_mean'] = X_test.iloc[:,123:154].mean(axis = 1)\n",
    "X_test['10월_엽록소_std'] = X_test.iloc[:,123:154].std(axis = 1)\n",
    "X_test['10월_엽록소_var'] = X_test.iloc[:,123:154].var(axis = 1)\n",
    "X_test['11월_엽록소_mean'] = X_test.iloc[:,154:182].mean(axis = 1)\n",
    "X_test['11월_엽록소_std'] = X_test.iloc[:,154:182].std(axis = 1)\n",
    "X_test['11월_엽록소_var'] = X_test.iloc[:,154:182].var(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['새순max'] = X_test.iloc[:,4:93].max(axis=1)\n",
    "X_test['새순min'] = X_test.iloc[:,4:93].min(axis=1)\n",
    "X_test['엽록소max'] = X_test.iloc[:,93:182].max(axis=1)\n",
    "X_test['엽록소min'] = X_test.iloc[:,93:182].min(axis=1)\n",
    "X_test['새순차이'] = X_test['새순max']-X_test['새순min']\n",
    "X_test['엽록소차이'] = X_test['엽록소max']-X_test['엽록소min']\n",
    "X_test['수고X수관폭'] = X_test['수고(m)']*X_test['수관폭평균']\n",
    "X_test['수관폭차이'] = X_test['수관폭2(max)']-X_test['수관폭1(min)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,89):\n",
    "    X_test[f'새순+엽록소_{i}'] = X_test.iloc[:,4:93].iloc[:,i]+X_test.iloc[:,93:182].iloc[:,i]\n",
    "for i in range(0,89):\n",
    "    X_test[f'새순-엽록소_{i}'] = X_test.iloc[:,4:93].iloc[:,i]-X_test.iloc[:,93:182].iloc[:,i]\n",
    "for i in range(0,89):\n",
    "    X_test[f'새순*엽록소_{i}'] = X_test.iloc[:,4:93].iloc[:,i]*X_test.iloc[:,93:182].iloc[:,i]\n",
    "for i in range(0,89):\n",
    "    X_test[f'새순/엽록소_{i}'] = X_test.iloc[:,4:93].iloc[:,i]/X_test.iloc[:,93:182].iloc[:,i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#base version\n",
    "def NMAE(true, pred):\n",
    "    mae = np.mean(np.abs(true - pred))\n",
    "    score = mae / np.mean(np.abs(true))\n",
    "    return score\n",
    "\n",
    "#cross_val custom version\n",
    "def NMAE_CV(clf, x, y):\n",
    "    pred = clf.predict(x)\n",
    "    mae = np.mean(np.abs(y - pred))\n",
    "    score = mae / np.mean(np.abs(y))\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NFOLDS = 10\n",
    "SEED = 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = list(X_train.columns) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline을 이용한 preprocessing\n",
    "def remove_outlier(X, q=0.02):  \n",
    "    df = pd.DataFrame(X)\n",
    "    return df.apply(lambda x: x.clip(x.quantile(q), x.quantile(1-q)), axis=0).values\n",
    "\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"outlier\", FunctionTransformer(remove_outlier, kw_args={'q':0.02})), \n",
    "        (\"scaler\", MinMaxScaler()),\n",
    "    ]\n",
    ")\n",
    " \n",
    "column_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "   ]\n",
    ")\n",
    "\n",
    "preprocessor = Pipeline(\n",
    "    steps=[\n",
    "        (\"column\", column_transformer), \n",
    "    ]\n",
    ")\n",
    "\n",
    "model = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocessor\", preprocessor), \n",
    "        (\"Regressor\", LGBMRegressor(objective=\"regression\", metric=\"mae\", random_state=SEED)),\n",
    "    ]\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#최적값으로 파이프라인 재설정(optuna를 이용해 preprocessing parameter tuning)\n",
    "model.set_params(preprocessor__column__num__outlier__kw_args =  {'q': 0.02}, preprocessor__column__num__scaler = MinMaxScaler())\n",
    "\n",
    "#전처리 파이프라인만 수행\n",
    "X_train = preprocessor.fit_transform(X_train, y_train)\n",
    "X_test = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(X_train)\n",
    "X_test = pd.DataFrame(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SelectPercentile을 이용해 최적 피처 수 결정\n",
    "fs = SelectPercentile(percentile=13).fit(X_train, y_train)\n",
    "X_train = fs.transform(X_train)\n",
    "X_test = fs.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(X_train)\n",
    "X_test = pd.DataFrame(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv('X_train_fine.csv', index = False)\n",
    "X_test.to_csv('X_test_fine.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2 = pd.read_csv('X_train_fine.csv')\n",
    "X_test_2 = pd.read_csv('X_test_fine.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seed 고정\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "seed_everything(42) # Seed 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optuna를 이용해 hyperparameter tuning\n",
    "xgb_best_params_1 = {'lambda': 0.002645916029508221,\n",
    "                     'alpha': 0.06770804282734474,\n",
    "                     'colsample_bytree': 0.42500508042724955,\n",
    "                     'subsample': 0.7135736798352763,\n",
    "                     'learning_rate': 0.0034491759962488127,\n",
    "                     'n_estimators': 2538,\n",
    "                     'max_depth': 4,\n",
    "                     'min_child_weight': 2,\n",
    "                     'objective': 'reg:squarederror',\n",
    "                     'tree_method': 'gpu_hist',\n",
    "                     'predictor': 'gpu_predictor'}\n",
    "\n",
    "xgb_best_params_2 = {'lambda': 0.059360963228304024,\n",
    "                     'alpha': 0.9856292525135064,\n",
    "                     'colsample_bytree': 0.4569397260113678,\n",
    "                     'subsample': 0.4754658082470086,\n",
    "                     'learning_rate': 0.0029407888288556297,\n",
    "                     'n_estimators': 2020,\n",
    "                     'max_depth': 11,\n",
    "                     'min_child_weight': 49,\n",
    "                     'objective': 'reg:squarederror',\n",
    "                     'tree_method': 'gpu_hist',\n",
    "                     'predictor': 'gpu_predictor'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#multi-kfold1(과적합 방지를 이용해 사용)\n",
    "xgb_pred_1 = []\n",
    "\n",
    "kfold_list = [4, 5, 6]\n",
    "for kfold in kfold_list:\n",
    "    print(f\"{kfold} Fold start\")\n",
    "    i = 0\n",
    "    xgb_nmae = []\n",
    "    kf = KFold(n_splits=kfold, random_state=42, shuffle=True)\n",
    "    for fold, (tr_idx, val_idx) in enumerate(kf.split(X_1)):\n",
    "        tr_x, tr_y = X_1.iloc[tr_idx], y.iloc[tr_idx]\n",
    "        val_x, val_y = X_1.iloc[val_idx], y.iloc[val_idx]\n",
    "\n",
    "        #사이킷 런 래퍼 XGB 학습\n",
    "        xgb = XGBRegressor(**xgb_best_params_1)\n",
    "        xgb.fit(tr_x, tr_y, eval_set = [(val_x, val_y)], early_stopping_rounds = 100, verbose = 50, eval_metric = 'mae')       \n",
    "        val_pred = xgb.predict(val_x).astype(int)\n",
    "        fold_nmae = NMAE(val_y, val_pred)\n",
    "        xgb_nmae.append(fold_nmae)\n",
    "        print(f\"{i + 1}/{kfold} Fold NMAE = {fold_nmae}\")\n",
    "        i += 1\n",
    "        fold_pred = xgb.predict(X_test_1)\n",
    "        xgb_pred_1.append(fold_pred)\n",
    "\n",
    "    print(f\"\\nAVG of NMAE = {np.mean(xgb_nmae)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KFold ensemble1\n",
    "xgb_pred_sum_1 = sum(xgb_pred_1)  \n",
    "xgb_pred_sum_1 /= len(xgb_pred_1)\n",
    "xgb_pred_sum_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#multi-kfold2\n",
    "xgb_pred_2 = []\n",
    "\n",
    "kfold_list = [4, 5, 6]\n",
    "for kfold in kfold_list:\n",
    "    print(f\"{kfold} Fold start\")\n",
    "    i = 0\n",
    "    xgb_nmae = []\n",
    "    kf = KFold(n_splits=kfold, random_state=42, shuffle=True)\n",
    "    for fold, (tr_idx, val_idx) in enumerate(kf.split(X_2)):\n",
    "        tr_x, tr_y = X_2.iloc[tr_idx], y.iloc[tr_idx]\n",
    "        val_x, val_y = X_2.iloc[val_idx], y.iloc[val_idx]\n",
    "\n",
    "        #사이킷 런 래퍼 XGB 학습\n",
    "        xgb = XGBRegressor(**xgb_best_params_2)\n",
    "        xgb.fit(tr_x, tr_y, eval_set = [(val_x, val_y)], early_stopping_rounds = 100, verbose = 50, eval_metric = 'mae')       \n",
    "        val_pred = xgb.predict(val_x).astype(int)\n",
    "        fold_nmae = NMAE(val_y, val_pred)\n",
    "        xgb_nmae.append(fold_nmae)\n",
    "        print(f\"{i + 1}/{kfold} Fold NMAE = {fold_nmae}\")\n",
    "        i += 1\n",
    "        fold_pred = xgb.predict(X_test_2)\n",
    "        xgb_pred_2.append(fold_pred)\n",
    "\n",
    "    print(f\"\\nAVG of NMAE = {np.mean(xgb_nmae)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KFold ensemble2\n",
    "xgb_pred_sum_2 = sum(xgb_pred_2)  \n",
    "xgb_pred_sum_2 /= len(xgb_pred_2)\n",
    "xgb_pred_sum_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_param = {'objective' : 'regression',\n",
    "            'device' : 'gpu',\n",
    "            'metric' : 'mae'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#multi-kfold1\n",
    "lgb_pred_1 = []\n",
    "\n",
    "kfold_list = [4, 5, 6]\n",
    "for kfold in kfold_list:\n",
    "    print(f\"{kfold} Fold start\")\n",
    "    i = 0\n",
    "    lgb_nmae = []\n",
    "    kf = KFold(n_splits=kfold, random_state=42, shuffle=True)\n",
    "    for fold, (tr_idx, val_idx) in enumerate(kf.split(X_1)):\n",
    "        tr_x, tr_y = X_1.iloc[tr_idx], y.iloc[tr_idx]\n",
    "        val_x, val_y = X_1.iloc[val_idx], y.iloc[val_idx]\n",
    "\n",
    "        lgb = LGBMRegressor(**lgb_param)\n",
    "        lgb.fit(tr_x, tr_y, eval_set = [(val_x, val_y)], early_stopping_rounds = 100, verbose = 50, eval_metric = 'mae')\n",
    "        val_pred = lgb.predict(val_x).astype(int)\n",
    "        fold_nmae = NMAE(val_y, val_pred)\n",
    "        lgb_nmae.append(fold_nmae)\n",
    "        print(f\"{i + 1}/{kfold} Fold NMAE = {fold_nmae}\")\n",
    "        i += 1\n",
    "        fold_pred = lgb.predict(X_test_1)\n",
    "        lgb_pred_1.append(fold_pred)\n",
    "\n",
    "    print(f\"\\nAVG of NMAE = {np.mean(lgb_nmae)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KFold ensemble1\n",
    "lgb_pred_sum_1 = sum(lgb_pred_1)  \n",
    "lgb_pred_sum_1 /= len(lgb_pred_1)\n",
    "lgb_pred_sum_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#multi-kfold2\n",
    "lgb_pred_2 = []\n",
    "\n",
    "kfold_list = [4, 5, 6]\n",
    "for kfold in kfold_list:\n",
    "    print(f\"{kfold} Fold start\")\n",
    "    i = 0\n",
    "    lgb_nmae = []\n",
    "    kf = KFold(n_splits=kfold, random_state=42, shuffle=True)\n",
    "    for fold, (tr_idx, val_idx) in enumerate(kf.split(X_2)):\n",
    "        tr_x, tr_y = X_2.iloc[tr_idx], y.iloc[tr_idx]\n",
    "        val_x, val_y = X_2.iloc[val_idx], y.iloc[val_idx]\n",
    "\n",
    "        lgb = LGBMRegressor(**lgb_param)\n",
    "        lgb.fit(tr_x, tr_y, eval_set = [(val_x, val_y)], early_stopping_rounds = 100, verbose = 50, eval_metric = 'mae')\n",
    "        val_pred = lgb.predict(val_x).astype(int)\n",
    "        fold_nmae = NMAE(val_y, val_pred)\n",
    "        lgb_nmae.append(fold_nmae)\n",
    "        print(f\"{i + 1}/{kfold} Fold NMAE = {fold_nmae}\")\n",
    "        i += 1\n",
    "        fold_pred = lgb.predict(X_test_2)\n",
    "        lgb_pred_2.append(fold_pred)\n",
    "\n",
    "    print(f\"\\nAVG of NMAE = {np.mean(lgb_nmae)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KFold ensemble2\n",
    "lgb_pred_sum_2 = sum(lgb_pred_2)  \n",
    "lgb_pred_sum_2 /= len(lgb_pred_2)\n",
    "lgb_pred_sum_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#multi-kfold1\n",
    "cat_pred_1 = []\n",
    "\n",
    "kfold_list = [4, 5, 6]\n",
    "for kfold in kfold_list:\n",
    "    print(f\"{kfold} Fold start\")\n",
    "    i = 0\n",
    "    cat_nmae = []\n",
    "    kf = KFold(n_splits=kfold, random_state=42, shuffle=True)\n",
    "    for fold, (tr_idx, val_idx) in enumerate(kf.split(X_1)):\n",
    "        tr_x, tr_y = X_1.iloc[tr_idx], y.iloc[tr_idx]\n",
    "        val_x, val_y = X_1.iloc[val_idx], y.iloc[val_idx]\n",
    "\n",
    "        cat = CatBoostRegressor(use_best_model = True,\n",
    "                                task_type = 'GPU',\n",
    "                                iterations = 10000, \n",
    "                                eval_metric = 'MAE')\n",
    "        cat.fit(tr_x, tr_y, eval_set = [(val_x, val_y)], early_stopping_rounds = 100, verbose = 50)\n",
    "        val_pred = cat.predict(val_x).astype(int)\n",
    "        fold_nmae = NMAE(val_y, val_pred)\n",
    "        cat_nmae.append(fold_nmae)\n",
    "        print(f\"{i + 1}/{kfold} Fold NMAE = {fold_nmae}\")\n",
    "        i += 1\n",
    "        fold_pred = cat.predict(X_test_1)\n",
    "        cat_pred_1.append(fold_pred)\n",
    "\n",
    "    print(f\"\\nAVG of NMAE = {np.mean(cat_nmae)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KFold ensemble1\n",
    "cat_pred_sum_1 = sum(cat_pred_1)  \n",
    "cat_pred_sum_1 /= len(cat_pred_1)\n",
    "cat_pred_sum_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#multi-kfold2\n",
    "cat_pred_2 = []\n",
    "\n",
    "kfold_list = [4, 5, 6]\n",
    "for kfold in kfold_list:\n",
    "    print(f\"{kfold} Fold start\")\n",
    "    i = 0\n",
    "    cat_nmae = []\n",
    "    kf = KFold(n_splits=kfold, random_state=42, shuffle=True)\n",
    "    for fold, (tr_idx, val_idx) in enumerate(kf.split(X_2)):\n",
    "        tr_x, tr_y = X_2.iloc[tr_idx], y.iloc[tr_idx]\n",
    "        val_x, val_y = X_2.iloc[val_idx], y.iloc[val_idx]\n",
    "\n",
    "        cat = CatBoostRegressor(use_best_model = True,\n",
    "                                task_type = 'GPU',\n",
    "                                iterations = 10000, \n",
    "                                eval_metric = 'MAE')\n",
    "        cat.fit(tr_x, tr_y, eval_set = [(val_x, val_y)], early_stopping_rounds = 100, verbose = 50)\n",
    "        val_pred = cat.predict(val_x).astype(int)\n",
    "        fold_nmae = NMAE(val_y, val_pred)\n",
    "        cat_nmae.append(fold_nmae)\n",
    "        print(f\"{i + 1}/{kfold} Fold NMAE = {fold_nmae}\")\n",
    "        i += 1\n",
    "        fold_pred = cat.predict(X_test_2)\n",
    "        cat_pred_2.append(fold_pred)\n",
    "\n",
    "    print(f\"\\nAVG of NMAE = {np.mean(cat_nmae)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KFold ensemble2\n",
    "cat_pred_sum_2 = sum(cat_pred_2)  \n",
    "cat_pred_sum_2 /= len(cat_pred_2)\n",
    "cat_pred_sum_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv(r'C:\\Users\\dlwks\\OneDrive\\바탕 화면\\VSCode\\DACON_CODE_REVIEW\\감귤 착과량\\sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission1 = submission.copy()\n",
    "submission2 = submission.copy()\n",
    "\n",
    "submission1['착과량(int)'] = xgb_pred_sum_1*0.4 + lgb_pred_sum_1*0.4 + cat_pred_sum_1*0.2\n",
    "submission2['착과량(int)'] = xgb_pred_sum_2*0.4 + lgb_pred_sum_2*0.4 + cat_pred_sum_2*0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['착과량(int)'] = submission1['착과량(int)']*0.8 + submission2['착과량(int)']*0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
